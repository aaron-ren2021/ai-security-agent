# å…¨é¢ PydanticAI ç‰ˆæœ¬ ,# orchestration / workflow
# - Router èˆ‡æ¯å€‹ä¸‹æ¸¸å°ˆå®¶éƒ½æ˜¯ PydanticAI Agent
# - äº¤æ£’èµ° router.tool handoffï¼Œä¸¦ç”¨ usage=ctx.usage è®“ç”¨é‡å›çŒåˆ°çˆ¶ run
# - å¤šè¼ª routingã€fallbackã€120å­—æ‘˜è¦
# - __main__ ç›´æ¥èµ° analyze() demo
# - ç›´æ¥å‘¼å«llm ç•¶ä½œrouter çµ¦å‡ºä¿¡å¿ƒåˆ†æ•¸æ±ºå®šå°ˆå®¶agent

import os
import json
import time
from enum import Enum
from typing import Literal, Optional, List, Dict, Any

from dotenv import load_dotenv
from pydantic import BaseModel, Field
from pydantic_ai import Agent, UsageLimits, RunContext
from pydantic_ai.exceptions import UsageLimitExceeded
from pydantic_ai.models.openai import OpenAIChatModel
from pydantic_ai.providers.azure import AzureProvider

from azure.ai.projects import AIProjectClient
from azure.identity import DefaultAzureCredential
from azure.ai.agents.models import ListSortOrder

# Azure AI Search æ•´åˆ
from src.services.stable.azure_ai_search import AzureAISearchExperimental, AzureSearchConfig
from src.tools.azure_aisearch_tool import azure_search_tool, AzureSearchToolInput, AzureSearchToolOutput

load_dotenv()

# ========== Env æª¢æŸ¥ ==========
DEPLOYMENT = os.getenv("AZURE_OPENAI_DEPLOYMENT")
AI_PROJECT_ENDPOINT = os.getenv("AZURE_AI_PROJECT_ENDPOINT")
REQUIRED_ENVS = ["AZURE_OPENAI_ENDPOINT", "AZURE_OPENAI_API_KEY", "OPENAI_API_VERSION"]
missing = [k for k in ["AZURE_OPENAI_DEPLOYMENT", "AZURE_AI_PROJECT_ENDPOINT", *REQUIRED_ENVS] if not os.getenv(k)]
if missing:
    raise RuntimeError(f"ç¼ºå°‘å¿…è¦ç’°å¢ƒè®Šæ•¸: {', '.join(missing)}")

# Azure AI Search ç’°å¢ƒè®Šæ•¸ï¼ˆå¯é¸ï¼‰
AZURE_SEARCH_SERVICE_NAME = os.getenv("AZURE_SEARCH_SERVICE_NAME")
AZURE_SEARCH_API_KEY = os.getenv("AZURE_SEARCH_API_KEY")
AZURE_SEARCH_INDEX_NAME = os.getenv("AZURE_SEARCH_INDEX_NAME", "documents")

# ========== è¦å‰‡èˆ‡å¸¸æ•¸ ==========
ROUTER_INSTRUCTIONS = os.getenv(
    "ROUTER_INSTRUCTIONS",
    (
        "ä½ æ˜¯è³‡å®‰è·¯ç”±å™¨ï¼Œåªè¼¸å‡º JSON(target, confidence)ã€‚\n"
        "è¦å‰‡ï¼š\n"
        "- æœ‰æ”»æ“Šè€…/IOC/TTP/å…¥ä¾µè·¡è±¡ â†’ threat_analysis\n"
        "- æœ‰ä¸»æ©Ÿ/åŸ /æœå‹™/ç‰ˆæœ¬/å¼±æƒ/èª¤è¨­ â†’ network_security\n"
        "- æœ‰å¸³è™Ÿ/å¯†ç¢¼/MFA/æ¬Šé™/ç™»å…¥ç•°å¸¸ â†’ account_security\n"
        "- æ¨¡ç³Šæˆ–é–’èŠ â†’ general_response\n"
        "confidence ä»‹æ–¼ 0~1ï¼›è‹¥æ¥µåº¦ä¸ç¢ºå®šï¼Œtarget=unknownã€‚"
    ),
)
SUMMARIZER_INSTRUCTIONS = (
    "è«‹ç”¢å‡º JSONï¼Œæ ¼å¼ç‚º {\"summary\": \"ä¸è¶…é120å­—çš„ç¹ä¸­æ‘˜è¦\", \"concluded\": å¸ƒæ—}ã€‚"
    "æœ‰æ˜ç¢ºè™•ç½®å»ºè­°/çµè«–æ™‚ concluded=trueï¼›å¦å‰‡ falseã€‚"
)

CONF_THRESHOLD = float(os.getenv("ROUTER_CONF_THRESHOLD", "0.55"))
_max_rounds_raw = os.getenv("ROUTER_MAX_ROUNDS", "2")
try:
    MAX_ROUNDS = int(_max_rounds_raw)
except ValueError:
    MAX_ROUNDS = 3

# å°ˆå®¶ Azure Agent IDsï¼ˆå¯åœ¨ .env è¦†è“‹ï¼‰
AGENT_IDS = {
    "threat_analysis": os.getenv("AGENT_THREAT_ID", "asst_wQTilJKeeNzL6dKTGXG5ynEW"),
    "network_security": os.getenv("AGENT_NETWORK_ID", "asst_Blv8Anlvv0FfP5bG7e19kGFU"),
    "account_security": os.getenv("AGENT_ACCOUNT_ID", "asst_89bKLUBlHjIFTRe6xqcejT8q"),
    "general_response": os.getenv("AGENT_GENERAL_ID", "asst_UIt2UKGS0cpTclQrOVm1XEfi"),
}

# ========== å‹åˆ¥ ==========
class AgentType(str, Enum):
    THREAT_ANALYSIS = "threat_analysis"
    NETWORK_SECURITY = "network_security"
    ACCOUNT_SECURITY = "account_security"
    GENERAL_RESPONSE = "general_response"
    UNKNOWN = "unknown"

class Route(BaseModel):
    target: Literal["threat_analysis", "network_security", "account_security", "general_response", "unknown"]
    confidence: float = Field(ge=0.0, le=1.0)

class SpecialistResult(BaseModel):
    target: str
    agent_id: Optional[str] = None
    response: Optional[str] = None
    error: Optional[str] = None
    latency_s: Optional[float] = None
    search_results: Optional[List[Dict[str, Any]]] = None  # æ–°å¢ï¼šæœå°‹çµæœ
    knowledge_used: bool = False  # æ–°å¢ï¼šæ˜¯å¦ä½¿ç”¨äº†çŸ¥è­˜åº«

class OrchestratedOutput(BaseModel):
    route: Route
    result: SpecialistResult
    steps: List[str] = Field(default_factory=list)
    summary: Optional[str] = None

class SumOut(BaseModel):
    summary: str
    concluded: bool  # é€™è¼ªæ˜¯å¦å·²æœ‰æ¸…æ¥šçµè«–/å»ºè­°

# ========== å…±ç”¨ LLM èˆ‡ Azure Project Client ==========
base_model = OpenAIChatModel(DEPLOYMENT, provider=AzureProvider())
project = AIProjectClient(credential=DefaultAzureCredential(), endpoint=AI_PROJECT_ENDPOINT)

# ========== Azure AI Search åˆå§‹åŒ– ==========
search_client = None
if AZURE_SEARCH_SERVICE_NAME:
    try:
        search_config = AzureSearchConfig(
            service_name=AZURE_SEARCH_SERVICE_NAME,
            api_key=AZURE_SEARCH_API_KEY,
            index_name=AZURE_SEARCH_INDEX_NAME,
            use_semantic_search=True
        )
        search_client = AzureAISearchExperimental(search_config)
        print(f"âœ“ Azure AI Search å·²åˆå§‹åŒ–: {AZURE_SEARCH_SERVICE_NAME}/{AZURE_SEARCH_INDEX_NAME}")
    except Exception as e:
        print(f"âš ï¸ Azure AI Search åˆå§‹åŒ–å¤±æ•—: {e}")
        search_client = None
else:
    print("â„¹ï¸ æœªè¨­å®š AZURE_SEARCH_SERVICE_NAMEï¼Œè·³é Azure AI Search åˆå§‹åŒ–")

# ========== Azure å‘¼å«å°è£ï¼ˆä¾›ä¸‹æ¸¸ Agent çš„ tool ä½¿ç”¨ï¼‰ ==========
def _call_azure_agent(agent_type: str, text: str, thread_id: Optional[str] = None, search_results: Optional[List[Dict[str, Any]]] = None) -> SpecialistResult:
    """å‘¼å« Azure Agentï¼Œå¯é¸æ“‡æ€§å‚³å…¥æœå°‹çµæœä»¥å¢å¼·å›æ‡‰ã€‚"""
    start = time.time()
    agent_id = AGENT_IDS.get(agent_type)
    if not agent_id:
        return SpecialistResult(target=agent_type, error=f"Unknown agent_type {agent_type}")
    
    try:
        ag = project.agents.get_agent(agent_id)
        # é‡ç”¨ thread_idï¼›æ²’æœ‰å°±æ–°å»º
        thread = project.agents.threads.create() if not thread_id else type("T", (), {"id": thread_id})
        
        # å¦‚æœæœ‰æœå°‹çµæœï¼ŒåŠ å…¥åˆ°æç¤ºä¸­
        enhanced_text = text
        if search_results:
            knowledge_context = "\n".join([
                f"ã€åƒè€ƒæ–‡ä»¶ã€‘ {doc.get('title', 'Unknown')}: {doc.get('content', '')[:200]}..."
                for doc in search_results[:3]  # åªå–å‰3å€‹æœ€ç›¸é—œçš„çµæœ
            ])
            enhanced_text = f"ã€çŸ¥è­˜åº«åƒè€ƒã€‘\n{knowledge_context}\n\nã€ç”¨æˆ¶æŸ¥è©¢ã€‘\n{text}"
        
        project.agents.messages.create(thread_id=thread.id, role="user", content=enhanced_text)
        run = project.agents.runs.create_and_process(thread_id=thread.id, agent_id=ag.id)
        
        if run.status == "failed":
            return SpecialistResult(
                target=agent_type, 
                agent_id=agent_id, 
                error=f"Run failed: {run.last_error}",
                search_results=search_results,
                knowledge_used=bool(search_results)
            )
        
        msgs = project.agents.messages.list(thread_id=thread.id, order=ListSortOrder.ASCENDING)
        replies = [m.text_messages[-1].text.value for m in msgs if m.role == "assistant" and getattr(m, "text_messages", None)]
        latency = round(time.time() - start, 3)
        
        return SpecialistResult(
            target=agent_type, 
            agent_id=agent_id, 
            response=(replies[-1] if replies else "(ç©ºå›æ‡‰)"), 
            latency_s=latency,
            search_results=search_results,
            knowledge_used=bool(search_results)
        )
    except Exception as e:
        return SpecialistResult(
            target=agent_type, 
            error=str(e), 
            latency_s=round(time.time()-start, 3),
            search_results=search_results,
            knowledge_used=bool(search_results)
        )

# ========== ä¸‹æ¸¸ï¼šPydanticAI åŸç”Ÿå°ˆå®¶ Agentsï¼ˆå„è‡ªæœ‰ tool ç›´å‘¼ Azureï¼‰ ==========
def make_specialist_agent(name: str) -> Agent[None, SpecialistResult]:
    tools = []
    
    # åŸºæœ¬ Azure Agent èª¿ç”¨å·¥å…·
    async def invoke_backend(_: RunContext[None], text: str, thread_id: Optional[str] = None) -> SpecialistResult:
        return _call_azure_agent(name, text, thread_id=thread_id)
    
    # æ·»åŠ  Azure AI Search å·¥å…·ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if search_client:
        search_tool = azure_search_tool(
            search_client,
            name=f"{name}_search",
            description=f"æŸ¥è©¢ {name} ç›¸é—œçš„çŸ¥è­˜åº«æ–‡æª”ï¼Œç”¨æ–¼å¢å¼·å›ç­”æº–ç¢ºæ€§ã€‚"
        )
        tools.append(search_tool)
    
    agent = Agent(
        base_model,
        output_type=SpecialistResult,
        tools=tools,
        instructions=f"""ä½ æ˜¯ {name} å°ˆå®¶ä»£ç†ã€‚ä½ æœ‰ä»¥ä¸‹èƒ½åŠ›ï¼š
        1. å‘¼å«å¾Œç«¯ Azure Agent è™•ç†è¤‡é›œåˆ†æ
        2. {'æŸ¥è©¢çŸ¥è­˜åº«æ–‡æª”ä»¥å¢å¼·å›ç­”' if search_client else 'ç›´æ¥å›æ‡‰æŸ¥è©¢'}
        
        è™•ç†æµç¨‹ï¼š
        1. å¦‚æœéœ€è¦åƒè€ƒæ–‡æª”æˆ–æœ€ä½³å¯¦è¸ï¼Œå…ˆä½¿ç”¨æœå°‹å·¥å…·
        2. çµåˆæœå°‹çµæœå’Œä½ çš„å°ˆæ¥­çŸ¥è­˜
        3. å¿…è¦æ™‚èª¿ç”¨å¾Œç«¯ Azure Agent é€²è¡Œæ·±åº¦åˆ†æ
        4. æä¾›çµæ§‹åŒ–çš„å°ˆæ¥­å›æ‡‰"""
    )
    
    @agent.tool
    async def invoke_backend_tool(_: RunContext[None], text: str, thread_id: Optional[str] = None) -> SpecialistResult:
        return _call_azure_agent(name, text, thread_id=thread_id)

    return agent

threat_agent   = make_specialist_agent("threat_analysis")
network_agent  = make_specialist_agent("network_security")
account_agent  = make_specialist_agent("account_security")
general_agent  = make_specialist_agent("general_response")

CHILDREN: Dict[str, Agent] = {
    "threat_analysis": threat_agent,
    "network_security": network_agent,
    "account_security": account_agent,
    "general_response": general_agent,
}

# ========== Router èˆ‡ Summarizerï¼ˆPydanticAIï¼‰ ==========
router = Agent(base_model, output_type=Route, instructions=ROUTER_INSTRUCTIONS)
summarizer = Agent(base_model, output_type=SumOut, instructions=SUMMARIZER_INSTRUCTIONS)

# Router çš„ handoff å·¥å…·ï¼šæŠŠ usage å’Œ thread_id äº¤çµ¦å­ä»£ç†
@router.tool
async def handoff(ctx: RunContext[None], target: str, text: str, thread_id: Optional[str] = None) -> SpecialistResult:
    child = CHILDREN.get(target, general_agent)
    # thread_id ä¹Ÿå‚³ä¸‹å»ï¼›usage ç”¨ ctx.usage
    return await child.run({"text": text, "thread_id": thread_id}, usage=ctx.usage)

# ========== å”èª¿å™¨ï¼šå¤šè¼ª + fallback + æ‘˜è¦ + usage é™åˆ¶ ==========
class Coordinator:
    def __init__(self, threshold: float = CONF_THRESHOLD, max_rounds: int = MAX_ROUNDS):
        self.threshold = threshold
        self.max_rounds = max_rounds
        self.history: List[str] = []
        self.thread_id: Optional[str] = None   # <â”€â”€ æ–°å¢ï¼šä¿å­˜ Azure thread

    def start_dialog(self):
        # é–‹ä¸€å€‹æ–° threadï¼›ä¹‹å¾Œ continue_dialog éƒ½é‡ç”¨
        self.thread_id = project.agents.threads.create().id

    def continue_dialog(self, text: str) -> OrchestratedOutput:
        if not self.thread_id:
            self.start_dialog()
        return self._run_core(text, thread_id=self.thread_id)

    # åŸ run() æ”¹æˆå‘¼å« coreï¼›ç‚ºäº†ç›¸å®¹ï¼Œä¹Ÿä¿ç•™ run() æœƒæ–°é–‹ thread
    def run(self, text: str) -> OrchestratedOutput:
        self.start_dialog()
        return self._run_core(text, thread_id=self.thread_id)

    def _route(self, text: str) -> Route:
        return router.run_sync(text, usage_limits=UsageLimits(request_limit=5, total_tokens_limit=2000)).output

    def _normalize(self, route: Route) -> str:
        tgt = route.target
        if route.confidence < self.threshold and tgt != AgentType.GENERAL_RESPONSE.value:
            tgt = AgentType.GENERAL_RESPONSE.value
        if tgt == AgentType.UNKNOWN.value:
            tgt = AgentType.GENERAL_RESPONSE.value
        return tgt

    def _delegate(self, target: str, text: str, thread_id: Optional[str]) -> SpecialistResult:
        """å§”è¨—çµ¦å°ˆå®¶ä»£ç†ï¼Œå¯é¸æ“‡æ€§å…ˆé€²è¡ŒçŸ¥è­˜æœå°‹ä»¥å¢å¼·å›æ‡‰ã€‚"""
        search_results = None
        
        # å¦‚æœ Azure AI Search å¯ç”¨ï¼Œå…ˆé€²è¡ŒçŸ¥è­˜æª¢ç´¢
        if search_client:
            try:
                # æ ¹æ“šä¸åŒå°ˆå®¶é¡å‹èª¿æ•´æœå°‹ç­–ç•¥
                search_filters = {
                    "threat_analysis": "category eq 'threat' or category eq 'malware' or category eq 'attack'",
                    "network_security": "category eq 'network' or category eq 'firewall' or category eq 'infrastructure'",
                    "account_security": "category eq 'identity' or category eq 'access' or category eq 'authentication'",
                    "general_response": None  # ä¸é™åˆ¶åˆ†é¡
                }
                
                filter_condition = search_filters.get(target)
                
                # åŸ·è¡Œæœå°‹
                hits = search_client.search(
                    query_text=text,
                    top_k=3,
                    filter=filter_condition,
                    semantic=True
                )
                
                if hits:
                    search_results = hits
                    print(f"ğŸ” ç‚º {target} æ‰¾åˆ° {len(hits)} å€‹ç›¸é—œæ–‡æª”")
            
            except Exception as e:
                print(f"âš ï¸ çŸ¥è­˜æœå°‹å¤±æ•—: {e}")
        
        # å‘¼å« Azure å¾Œç«¯ï¼Œå‚³å…¥æœå°‹çµæœ
        return _call_azure_agent(target, text, thread_id=thread_id, search_results=search_results)

    def _summarize(self, user_input: str, agent_response: str) -> SumOut:
        hist = "\n".join(self.history)
        cur  = f"User: {user_input}\nAssistant: {agent_response}"
        full = f"{hist}\n{cur}" if hist else cur
        def _summarize_text(text: str) -> SumOut:
            r = summarizer.run_sync(text, usage_limits=UsageLimits(request_limit=3, total_tokens_limit=1000))
            return r.output

        try:
            out = _summarize_text(full)
        except UsageLimitExceeded:
            # è‹¥ç´¯ç©æ­·å²éé•·å°è‡´è¶…é‡ï¼Œæ”¹ç”¨ç•¶å‰è¼ªå°è©±é‡æ–°æ‘˜è¦
            try:
                out = _summarize_text(cur)
            except UsageLimitExceeded:
                # é€£å–®è¼ªéƒ½å¤±æ•—æ™‚ï¼Œç›´æ¥ fallback åˆ°éœæ…‹æ‘˜è¦ï¼Œé¿å…ä¸­æ–·æµç¨‹
                truncated = (agent_response or "ç„¡å›æ‡‰").strip()
                if len(truncated) > 120:
                    truncated = truncated[:117] + "..."
                return SumOut(summary=f"æ‘˜è¦å¤±æ•—ï¼ˆè¶…å‡ºä½¿ç”¨é™åˆ¶ï¼‰ã€‚é‡é»ï¼š{truncated}", concluded=False)

        # å¼·éŸŒè™•ç†
        if not out or not isinstance(out, SumOut):
            return SumOut(summary="ç„¡éœ€æ‘˜è¦", concluded=False)
        if not (out.summary or "").strip():
            out.summary = "ç„¡éœ€æ‘˜è¦"
        return out

    def _run_core(self, text: str, thread_id: Optional[str]) -> OrchestratedOutput:
        steps, route, sres = [], None, None
        cur = text
        round_usages: List[Dict[str, Any]] = []   # <â”€â”€ æ¯è¼ª usage è¨˜éŒ„

        for i in range(1, self.max_rounds + 1):
            steps.append(f"Round {i}: route")
            r = router.run_sync(cur, usage_limits=UsageLimits(request_limit=5, total_tokens_limit=2000))
            route = r.output
            steps.append(f"  -> {route.target} ({route.confidence})")
            # è¨˜ usageï¼ˆç¤¾ç¾¤å¸¸ç”¨æ³•ï¼šå¾ RunResult å– usage å½™ç¸½ï¼‰:contentReference[oaicite:3]{index=3}
            # usage å¯èƒ½åœ¨æŸäº›æƒ…æ³ä¸‹ä¸æ˜¯å…·æœ‰ model_dump çš„ç‰©ä»¶ï¼ˆä¾‹å¦‚è¢«è¦†å¯«æˆå‡½å¼ï¼‰ï¼Œéœ€å®‰å…¨æª¢æŸ¥
            if getattr(r, "usage", None) and hasattr(r.usage, "model_dump"):
                try:
                    round_usages.append({"phase": f"route_{i}", **r.usage.model_dump()})
                except Exception as e:  # æ¥µç«¯å¤±æ•—å¿½ç•¥ï¼Œä¸å½±éŸ¿ä¸»æµç¨‹
                    steps.append(f"  (warn) route usage serialize failed: {e}")

            tgt = self._normalize(route)
            steps.append(f"  handoff -> {tgt}")

            sres = self._delegate(tgt, cur, thread_id)

            # é€™è¼ªæ‘˜è¦ + ææ—©åœæ­¢åˆ¤æ–·
            sum_out = self._summarize(cur, (sres.response or ""))
            steps.append(f"  summarized: concluded={sum_out.concluded}")
            # æŠŠæ‘˜è¦ä¹Ÿå¯«å› thread çµ¦ä¸‹ä¸€è¼ª
            project.agents.messages.create(thread_id=thread_id, role="assistant", content=f"[æ‘˜è¦]\n{sum_out.summary}")
            self.history.append(sum_out.summary)
            if len(self.history) > 20:
                self.history = self.history[-20:]

            if sres and not sres.error and sum_out.concluded:
                steps.append("  concluded=true -> stop")
                return OrchestratedOutput(route=route, result=sres, steps=steps, summary=sum_out.summary)

            if sres and not sres.error:
                steps.append("  ok but not concluded -> maybe next round")
            else:
                steps.append("  error -> retry")
                cur = "[RETRY]\n" + cur

        # è¶…é MAX_ROUNDSï¼šfallback
        steps.append("Fallback: general_response")
        route = Route(target=AgentType.GENERAL_RESPONSE.value, confidence=1.0)
        sres = self._delegate("general_response", cur, thread_id)
        sum_out = self._summarize(cur, (sres.response or ""))
        steps.append("  finalized with fallback")
        project.agents.messages.create(thread_id=thread_id, role="assistant", content=f"[æ‘˜è¦]\n{sum_out.summary}")

        # Azure Agent ç›®å‰ç„¡æ³•å›å‚³ usageï¼›åªæœƒå½™æ•´è·¯ç”±éšæ®µçš„ç”¨é‡è³‡è¨Š
        # æŠŠ usage summary æ”¾é€² steps
        steps.append(f"USAGE_SUMMARY={json.dumps(round_usages, ensure_ascii=False)}")
        return OrchestratedOutput(route=route, result=sres, steps=steps, summary=sum_out.summary)

coordinator = Coordinator()

def analyze(text: str) -> Dict[str, Any]:
    out = coordinator.run(text)
    return json.loads(json.dumps(out.model_dump(), ensure_ascii=False))

if __name__ == "__main__":
    samples = [
        "ä¸»æ©Ÿ 192.168.1.1 ç™¼ç¾æœªæˆæ¬Šçš„ SSH ç™»å…¥ï¼Œè«‹å”åŠ©åˆ†æä¸¦æå‡ºå»ºè­°ã€‚",
        "ä»€éº¼æ˜¯é›¶ä¿¡ä»»ç¶²è·¯æ¶æ§‹ï¼Ÿè«‹èªªæ˜å…¶æ ¸å¿ƒåŸå‰‡ã€‚",
        "ç™¼ç¾ä½¿ç”¨è€…å¸³è™Ÿç•°å¸¸ç™»å…¥è¡Œç‚ºï¼Œå¦‚ä½•é€²è¡Œèª¿æŸ¥ï¼Ÿ",
        "ç¶²è·¯æƒæç™¼ç¾é–‹æ”¾çš„ RDP åŸ ï¼Œæœ‰ä»€éº¼å®‰å…¨é¢¨éšªï¼Ÿ",
    ]
    
    print(f"ğŸ” Azure AI Search ç‹€æ…‹: {'å·²å•Ÿç”¨' if search_client else 'æœªå•Ÿç”¨'}")
    print(f"ğŸ“Š æ¸¬è©¦æ¡ˆä¾‹æ•¸é‡: {len(samples)}")
    print("="*60)
    
    for i, s in enumerate(samples, 1):
        print(f"\nğŸ”¹ æ¸¬è©¦æ¡ˆä¾‹ {i}/{len(samples)}")
        print("=== INPUT ===")
        print(s)
        print("=== OUTPUT ===")
        result = analyze(s)
        print(json.dumps(result, ensure_ascii=False, indent=2))
        
        # é¡¯ç¤ºæ˜¯å¦ä½¿ç”¨äº†çŸ¥è­˜åº«
        if result.get('result', {}).get('knowledge_used'):
            print("ğŸ’¡ æ­¤å›æ‡‰ä½¿ç”¨äº†çŸ¥è­˜åº«æª¢ç´¢")
        
        print("-" * 60)
